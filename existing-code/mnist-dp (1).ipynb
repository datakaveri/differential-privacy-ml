{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Author: Sejal Gupta, Twisha Bansal\n#References: \n#https://opacus.ai/tutorials/building_image_classifier#Test-the-network-on-test-data\n#https://arxiv.org/pdf/1607.00133.pdf\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nMAX_GRAD_NORM = 1.1 #gradient norm bound 'C'\nEPSILON = 50.0      #privacy loss, should be small for higher privacy\nDELTA = 1e-4        #ε-differential privacy is broken with probability δ (which is preferably smaller than 1/|d|)\nEPOCHS = 20\nLR = 1e-2           #step size at each iteration","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:35.276250Z","iopub.execute_input":"2022-12-01T09:39:35.276685Z","iopub.status.idle":"2022-12-01T09:39:35.305885Z","shell.execute_reply.started":"2022-12-01T09:39:35.276597Z","shell.execute_reply":"2022-12-01T09:39:35.305109Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64  #logical batch size, which defines how often the model is updated and how much DP noise is added\nMAX_PHYSICAL_BATCH_SIZE = 128 #physical batch size, which defines how many samples we process at a time","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:35.307511Z","iopub.execute_input":"2022-12-01T09:39:35.307999Z","iopub.status.idle":"2022-12-01T09:39:35.311652Z","shell.execute_reply.started":"2022-12-01T09:39:35.307970Z","shell.execute_reply":"2022-12-01T09:39:35.310942Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n#pre-computed\nMNIST_MEAN = (0.1307,)\nMNIST_STD_DEV = (0.3081,)\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(MNIST_MEAN, MNIST_STD_DEV),\n])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:35.312876Z","iopub.execute_input":"2022-12-01T09:39:35.313362Z","iopub.status.idle":"2022-12-01T09:39:37.487817Z","shell.execute_reply.started":"2022-12-01T09:39:35.313336Z","shell.execute_reply":"2022-12-01T09:39:37.486473Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import MNIST\n\nDATA_ROOT = '/files/'\n\n#load the MNIST(handwritten digits) dataset\ntrain_dataset = MNIST(\n    root=DATA_ROOT, train=True, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n)\n\ntest_dataset = MNIST(\n    root=DATA_ROOT, train=False, download=True, transform=transform)\n\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:37.490203Z","iopub.execute_input":"2022-12-01T09:39:37.490775Z","iopub.status.idle":"2022-12-01T09:39:39.337092Z","shell.execute_reply.started":"2022-12-01T09:39:37.490741Z","shell.execute_reply":"2022-12-01T09:39:39.336055Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779601b5daa9476c91b98b16f4dc6c57"}},"metadata":{}},{"name":"stdout","text":"Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz to /files/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c5c34961cb4660a0f4f580f380b3ff"}},"metadata":{}},{"name":"stdout","text":"Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz to /files/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3320f40e289428291740a4304c4bb52"}},"metadata":{}},{"name":"stdout","text":"Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz to /files/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5fc8b6c697246c5954f24f76b641018"}},"metadata":{}},{"name":"stdout","text":"Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:39.338232Z","iopub.execute_input":"2022-12-01T09:39:39.338499Z","iopub.status.idle":"2022-12-01T09:39:39.343316Z","shell.execute_reply.started":"2022-12-01T09:39:39.338475Z","shell.execute_reply":"2022-12-01T09:39:39.341947Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#defining the classification model(convolutional neural network)\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:39.344583Z","iopub.execute_input":"2022-12-01T09:39:39.345090Z","iopub.status.idle":"2022-12-01T09:39:39.356984Z","shell.execute_reply.started":"2022-12-01T09:39:39.345020Z","shell.execute_reply":"2022-12-01T09:39:39.355919Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = Net()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:39.357995Z","iopub.execute_input":"2022-12-01T09:39:39.358399Z","iopub.status.idle":"2022-12-01T09:39:39.387131Z","shell.execute_reply.started":"2022-12-01T09:39:39.358365Z","shell.execute_reply":"2022-12-01T09:39:39.386101Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install opacus","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:39:39.388154Z","iopub.execute_input":"2022-12-01T09:39:39.388466Z","iopub.status.idle":"2022-12-01T09:42:03.843021Z","shell.execute_reply.started":"2022-12-01T09:39:39.388437Z","shell.execute_reply":"2022-12-01T09:42:03.840872Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting opacus\n  Downloading opacus-1.3.0-py3-none-any.whl (216 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.9/216.9 kB\u001b[0m \u001b[31m908.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.7/site-packages (from opacus) (1.11.0+cpu)\nRequirement already satisfied: scipy>=1.2 in /opt/conda/lib/python3.7/site-packages (from opacus) (1.7.3)\nCollecting functorch\n  Downloading functorch-1.13.0-py2.py3-none-any.whl (2.1 kB)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from opacus) (1.21.6)\nRequirement already satisfied: opt-einsum>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from opacus) (3.3.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8->opacus) (4.4.0)\nCollecting torch>=1.8\n  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (0.37.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (59.8.0)\nInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, functorch, opacus\n  Attempting uninstall: torch\n    Found existing installation: torch 1.11.0+cpu\n    Uninstalling torch-1.11.0+cpu:\n      Successfully uninstalled torch-1.11.0+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchvision 0.12.0+cpu requires torch==1.11.0, but you have torch 1.13.0 which is incompatible.\ntorchtext 0.12.0 requires torch==1.11.0, but you have torch 1.13.0 which is incompatible.\ntorchaudio 0.11.0+cpu requires torch==1.11.0, but you have torch 1.13.0 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\nallennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed functorch-1.13.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 opacus-1.3.0 torch-1.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from opacus.validators import ModuleValidator\n\nerrors = ModuleValidator.validate(model, strict=False)\nerrors[-5:]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:42:03.845349Z","iopub.execute_input":"2022-12-01T09:42:03.845819Z","iopub.status.idle":"2022-12-01T09:42:04.667412Z","shell.execute_reply.started":"2022-12-01T09:42:03.845780Z","shell.execute_reply":"2022-12-01T09:42:04.665508Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device(\"cpu\")\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:42:04.672106Z","iopub.execute_input":"2022-12-01T09:42:04.672583Z","iopub.status.idle":"2022-12-01T09:42:04.679327Z","shell.execute_reply.started":"2022-12-01T09:42:04.672540Z","shell.execute_reply":"2022-12-01T09:42:04.678068Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:42:04.680653Z","iopub.execute_input":"2022-12-01T09:42:04.682276Z","iopub.status.idle":"2022-12-01T09:42:04.695476Z","shell.execute_reply.started":"2022-12-01T09:42:04.682205Z","shell.execute_reply":"2022-12-01T09:42:04.694333Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def accuracy(preds, labels):\n    return (preds == labels).mean()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:42:04.697750Z","iopub.execute_input":"2022-12-01T09:42:04.698616Z","iopub.status.idle":"2022-12-01T09:42:04.710864Z","shell.execute_reply.started":"2022-12-01T09:42:04.698569Z","shell.execute_reply":"2022-12-01T09:42:04.709430Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from opacus import PrivacyEngine\n\nprivacy_engine = PrivacyEngine()\n\nmodel, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n    module=model,\n    optimizer=optimizer,\n    data_loader=train_loader,\n    epochs=EPOCHS,\n    target_epsilon=EPSILON,\n    target_delta=DELTA,\n    max_grad_norm=MAX_GRAD_NORM,\n)\n\n#sigma depends on epsilon and delta, get the noise scale sigma from the target epsilon and target delta provided\nprint(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:42:04.712859Z","iopub.execute_input":"2022-12-01T09:42:04.713290Z","iopub.status.idle":"2022-12-01T09:44:24.063966Z","shell.execute_reply.started":"2022-12-01T09:42:04.713252Z","shell.execute_reply":"2022-12-01T09:44:24.062334Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using sigma=0.3024864196777344 and C=1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom opacus.utils.batch_memory_manager import BatchMemoryManager\n\n#function to train the model\ndef train(model, train_loader, optimizer, epoch, device):\n    model.train()\n    criterion = nn.CrossEntropyLoss()\n\n    losses = []\n    top1_acc = []\n    \n    #To balance peak memory requirement, which is proportional to batch_size^2, and training performance, use BatchMemoryManager\n    with BatchMemoryManager(\n        data_loader=train_loader, \n        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n        optimizer=optimizer\n    ) as memory_safe_data_loader:\n\n        for i, (images, target) in enumerate(memory_safe_data_loader):   \n            optimizer.zero_grad()\n            images = images.to(device)\n            target = target.to(device)\n\n            # compute output\n            output = model(images)\n            loss = criterion(output, target)\n\n            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n            labels = target.detach().cpu().numpy()\n\n            # measure accuracy and record loss\n            acc = accuracy(preds, labels)\n\n            losses.append(loss.item())\n            top1_acc.append(acc)\n\n            loss.backward()\n            optimizer.step()\n\n            if (i+1) % 200 == 0:\n                epsilon = privacy_engine.get_epsilon(DELTA)\n                print(\n                    f\"\\tTrain Epoch: {epoch} \\t\"\n                    f\"Loss: {np.mean(losses):.6f} \"\n                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n                )","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:44:24.068135Z","iopub.execute_input":"2022-12-01T09:44:24.069164Z","iopub.status.idle":"2022-12-01T09:44:24.080843Z","shell.execute_reply.started":"2022-12-01T09:44:24.069126Z","shell.execute_reply":"2022-12-01T09:44:24.079249Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#function to test the model\ndef test(model, test_loader, device):\n    model.eval()\n    criterion = nn.CrossEntropyLoss()\n    losses = []\n    top1_acc = []\n\n    with torch.no_grad():\n        for images, target in test_loader:\n            images = images.to(device)\n            target = target.to(device)\n\n            output = model(images)\n            loss = criterion(output, target)\n            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n            labels = target.detach().cpu().numpy()\n            acc = accuracy(preds, labels)\n\n            losses.append(loss.item())\n            top1_acc.append(acc)\n\n    top1_avg = np.mean(top1_acc)\n\n    print(\n        f\"\\tTest set:\"\n        f\"Loss: {np.mean(losses):.6f} \"\n        f\"Acc: {top1_avg * 100:.6f} \"\n    )\n    return np.mean(top1_acc)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:44:24.082399Z","iopub.execute_input":"2022-12-01T09:44:24.083007Z","iopub.status.idle":"2022-12-01T09:44:24.101286Z","shell.execute_reply.started":"2022-12-01T09:44:24.082956Z","shell.execute_reply":"2022-12-01T09:44:24.098982Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nfor epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n    train(model, train_loader, optimizer, epoch + 1, device)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:44:24.102969Z","iopub.execute_input":"2022-12-01T09:44:24.103373Z","iopub.status.idle":"2022-12-01T09:57:40.058690Z","shell.execute_reply.started":"2022-12-01T09:44:24.103340Z","shell.execute_reply":"2022-12-01T09:57:40.056957Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/20 [00:00<?, ?epoch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ead1d1cf1f4c8499deaac5235fdd95"}},"metadata":{}},{"name":"stdout","text":"\tTrain Epoch: 1 \tLoss: 2.287196 Acc@1: 13.569050 (ε = 9.66, δ = 0.0001)\n\tTrain Epoch: 1 \tLoss: 2.254486 Acc@1: 16.829012 (ε = 11.30, δ = 0.0001)\n\tTrain Epoch: 1 \tLoss: 2.211812 Acc@1: 20.121011 (ε = 12.57, δ = 0.0001)\n\tTrain Epoch: 1 \tLoss: 2.162817 Acc@1: 22.985064 (ε = 13.64, δ = 0.0001)\n\tTrain Epoch: 2 \tLoss: 1.781397 Acc@1: 38.885069 (ε = 15.16, δ = 0.0001)\n\tTrain Epoch: 2 \tLoss: 1.730111 Acc@1: 40.813174 (ε = 15.96, δ = 0.0001)\n\tTrain Epoch: 2 \tLoss: 1.679309 Acc@1: 42.479926 (ε = 16.71, δ = 0.0001)\n\tTrain Epoch: 2 \tLoss: 1.644596 Acc@1: 43.698369 (ε = 17.41, δ = 0.0001)\n\tTrain Epoch: 3 \tLoss: 1.434348 Acc@1: 51.482871 (ε = 18.53, δ = 0.0001)\n\tTrain Epoch: 3 \tLoss: 1.418786 Acc@1: 52.430807 (ε = 19.15, δ = 0.0001)\n\tTrain Epoch: 3 \tLoss: 1.398395 Acc@1: 53.547450 (ε = 19.76, δ = 0.0001)\n\tTrain Epoch: 3 \tLoss: 1.384866 Acc@1: 54.536790 (ε = 20.34, δ = 0.0001)\n\tTrain Epoch: 4 \tLoss: 1.280211 Acc@1: 60.408074 (ε = 21.28, δ = 0.0001)\n\tTrain Epoch: 4 \tLoss: 1.269450 Acc@1: 60.832194 (ε = 21.82, δ = 0.0001)\n\tTrain Epoch: 4 \tLoss: 1.268953 Acc@1: 61.253469 (ε = 22.34, δ = 0.0001)\n\tTrain Epoch: 4 \tLoss: 1.266378 Acc@1: 61.620031 (ε = 22.86, δ = 0.0001)\n\tTrain Epoch: 5 \tLoss: 1.215132 Acc@1: 64.714207 (ε = 23.70, δ = 0.0001)\n\tTrain Epoch: 5 \tLoss: 1.218674 Acc@1: 64.991278 (ε = 24.18, δ = 0.0001)\n\tTrain Epoch: 5 \tLoss: 1.211218 Acc@1: 65.248919 (ε = 24.66, δ = 0.0001)\n\tTrain Epoch: 5 \tLoss: 1.212706 Acc@1: 65.542615 (ε = 25.13, δ = 0.0001)\n\tTrain Epoch: 6 \tLoss: 1.208127 Acc@1: 67.344228 (ε = 25.91, δ = 0.0001)\n\tTrain Epoch: 6 \tLoss: 1.202459 Acc@1: 67.605974 (ε = 26.36, δ = 0.0001)\n\tTrain Epoch: 6 \tLoss: 1.197281 Acc@1: 68.044140 (ε = 26.80, δ = 0.0001)\n\tTrain Epoch: 6 \tLoss: 1.192200 Acc@1: 68.379073 (ε = 27.24, δ = 0.0001)\n\tTrain Epoch: 7 \tLoss: 1.203616 Acc@1: 69.868183 (ε = 27.96, δ = 0.0001)\n\tTrain Epoch: 7 \tLoss: 1.190953 Acc@1: 70.033044 (ε = 28.38, δ = 0.0001)\n\tTrain Epoch: 7 \tLoss: 1.191340 Acc@1: 70.371745 (ε = 28.80, δ = 0.0001)\n\tTrain Epoch: 7 \tLoss: 1.184186 Acc@1: 70.562799 (ε = 29.21, δ = 0.0001)\n\tTrain Epoch: 8 \tLoss: 1.175886 Acc@1: 71.905606 (ε = 29.90, δ = 0.0001)\n\tTrain Epoch: 8 \tLoss: 1.159042 Acc@1: 72.532942 (ε = 30.30, δ = 0.0001)\n\tTrain Epoch: 8 \tLoss: 1.160828 Acc@1: 72.718321 (ε = 30.70, δ = 0.0001)\n\tTrain Epoch: 8 \tLoss: 1.162337 Acc@1: 72.742669 (ε = 31.09, δ = 0.0001)\n\tTrain Epoch: 9 \tLoss: 1.146251 Acc@1: 74.077722 (ε = 31.75, δ = 0.0001)\n\tTrain Epoch: 9 \tLoss: 1.172647 Acc@1: 73.685002 (ε = 32.14, δ = 0.0001)\n\tTrain Epoch: 9 \tLoss: 1.167764 Acc@1: 73.647921 (ε = 32.52, δ = 0.0001)\n\tTrain Epoch: 9 \tLoss: 1.175271 Acc@1: 73.687780 (ε = 32.89, δ = 0.0001)\n\tTrain Epoch: 10 \tLoss: 1.091646 Acc@1: 75.979034 (ε = 33.53, δ = 0.0001)\n\tTrain Epoch: 10 \tLoss: 1.138021 Acc@1: 75.356833 (ε = 33.90, δ = 0.0001)\n\tTrain Epoch: 10 \tLoss: 1.136603 Acc@1: 75.304142 (ε = 34.26, δ = 0.0001)\n\tTrain Epoch: 10 \tLoss: 1.131367 Acc@1: 75.444851 (ε = 34.63, δ = 0.0001)\n\tTrain Epoch: 11 \tLoss: 1.172257 Acc@1: 75.577378 (ε = 35.24, δ = 0.0001)\n\tTrain Epoch: 11 \tLoss: 1.176171 Acc@1: 75.385505 (ε = 35.60, δ = 0.0001)\n\tTrain Epoch: 11 \tLoss: 1.168123 Acc@1: 75.614291 (ε = 35.95, δ = 0.0001)\n\tTrain Epoch: 11 \tLoss: 1.167806 Acc@1: 75.799797 (ε = 36.31, δ = 0.0001)\n\tTrain Epoch: 12 \tLoss: 1.134056 Acc@1: 76.401199 (ε = 36.90, δ = 0.0001)\n\tTrain Epoch: 12 \tLoss: 1.122392 Acc@1: 76.609080 (ε = 37.25, δ = 0.0001)\n\tTrain Epoch: 12 \tLoss: 1.124129 Acc@1: 76.786496 (ε = 37.59, δ = 0.0001)\n\tTrain Epoch: 12 \tLoss: 1.131265 Acc@1: 76.731026 (ε = 37.94, δ = 0.0001)\n\tTrain Epoch: 13 \tLoss: 1.183660 Acc@1: 76.528148 (ε = 38.52, δ = 0.0001)\n\tTrain Epoch: 13 \tLoss: 1.159740 Acc@1: 76.715062 (ε = 38.85, δ = 0.0001)\n\tTrain Epoch: 13 \tLoss: 1.134474 Acc@1: 77.141380 (ε = 39.19, δ = 0.0001)\n\tTrain Epoch: 13 \tLoss: 1.128879 Acc@1: 77.185765 (ε = 39.53, δ = 0.0001)\n\tTrain Epoch: 14 \tLoss: 1.166438 Acc@1: 77.497711 (ε = 40.09, δ = 0.0001)\n\tTrain Epoch: 14 \tLoss: 1.151674 Acc@1: 77.663362 (ε = 40.42, δ = 0.0001)\n\tTrain Epoch: 14 \tLoss: 1.142245 Acc@1: 77.962299 (ε = 40.75, δ = 0.0001)\n\tTrain Epoch: 14 \tLoss: 1.132618 Acc@1: 78.012024 (ε = 41.08, δ = 0.0001)\n\tTrain Epoch: 15 \tLoss: 1.132132 Acc@1: 77.875056 (ε = 41.63, δ = 0.0001)\n\tTrain Epoch: 15 \tLoss: 1.127751 Acc@1: 78.179526 (ε = 41.95, δ = 0.0001)\n\tTrain Epoch: 15 \tLoss: 1.118203 Acc@1: 78.408264 (ε = 42.28, δ = 0.0001)\n\tTrain Epoch: 15 \tLoss: 1.132003 Acc@1: 78.235351 (ε = 42.60, δ = 0.0001)\n\tTrain Epoch: 16 \tLoss: 1.040730 Acc@1: 79.279262 (ε = 43.14, δ = 0.0001)\n\tTrain Epoch: 16 \tLoss: 1.083068 Acc@1: 79.070313 (ε = 43.45, δ = 0.0001)\n\tTrain Epoch: 16 \tLoss: 1.112835 Acc@1: 78.846173 (ε = 43.77, δ = 0.0001)\n\tTrain Epoch: 16 \tLoss: 1.110066 Acc@1: 79.029000 (ε = 44.08, δ = 0.0001)\n\tTrain Epoch: 17 \tLoss: 1.126345 Acc@1: 79.301693 (ε = 44.61, δ = 0.0001)\n\tTrain Epoch: 17 \tLoss: 1.137367 Acc@1: 79.202565 (ε = 44.93, δ = 0.0001)\n\tTrain Epoch: 17 \tLoss: 1.121014 Acc@1: 79.241579 (ε = 45.24, δ = 0.0001)\n\tTrain Epoch: 17 \tLoss: 1.110832 Acc@1: 79.333439 (ε = 45.55, δ = 0.0001)\n\tTrain Epoch: 18 \tLoss: 1.137308 Acc@1: 79.559276 (ε = 46.07, δ = 0.0001)\n\tTrain Epoch: 18 \tLoss: 1.123938 Acc@1: 79.591558 (ε = 46.37, δ = 0.0001)\n\tTrain Epoch: 18 \tLoss: 1.112813 Acc@1: 79.809378 (ε = 46.68, δ = 0.0001)\n\tTrain Epoch: 18 \tLoss: 1.096535 Acc@1: 80.068577 (ε = 46.98, δ = 0.0001)\n\tTrain Epoch: 19 \tLoss: 1.117189 Acc@1: 79.763039 (ε = 47.50, δ = 0.0001)\n\tTrain Epoch: 19 \tLoss: 1.086918 Acc@1: 80.102981 (ε = 47.80, δ = 0.0001)\n\tTrain Epoch: 19 \tLoss: 1.087907 Acc@1: 80.097673 (ε = 48.10, δ = 0.0001)\n\tTrain Epoch: 19 \tLoss: 1.089699 Acc@1: 80.242026 (ε = 48.40, δ = 0.0001)\n\tTrain Epoch: 20 \tLoss: 1.080150 Acc@1: 80.695197 (ε = 48.90, δ = 0.0001)\n\tTrain Epoch: 20 \tLoss: 1.072986 Acc@1: 80.726715 (ε = 49.20, δ = 0.0001)\n\tTrain Epoch: 20 \tLoss: 1.090684 Acc@1: 80.501959 (ε = 49.50, δ = 0.0001)\n\tTrain Epoch: 20 \tLoss: 1.094276 Acc@1: 80.374349 (ε = 49.79, δ = 0.0001)\n","output_type":"stream"}]},{"cell_type":"code","source":"top1_acc = test(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:57:40.060183Z","iopub.execute_input":"2022-12-01T09:57:40.060491Z","iopub.status.idle":"2022-12-01T09:57:42.303172Z","shell.execute_reply.started":"2022-12-01T09:57:40.060466Z","shell.execute_reply":"2022-12-01T09:57:42.302131Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\tTest set:Loss: 0.529818 Acc: 90.376194 \n","output_type":"stream"}]}]}